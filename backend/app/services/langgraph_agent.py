"""
ì„œìš¸ì•„ì‚°ë³‘ì› AI í”Œë«í¼ - LangGraph ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
ì˜ë£Œì§„ì„ ìœ„í•œ ì§€ëŠ¥í˜• AI ì—ì´ì „íŠ¸
"""
from typing import Dict, List, Any, Optional, TypedDict, Literal, Annotated
from langchain_core.messages import BaseMessage, AIMessage, HumanMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from langchain_core.tools import BaseTool, tool
# from langchain.agents import AgentExecutor  # Not needed for LangGraph
from pydantic import BaseModel, Field
import asyncio
import logging
from datetime import datetime
import json
import uuid

from vector_store import medical_vector_store
from graph_rag import medical_graph_rag
from qwen_model import qwen_model

logger = logging.getLogger(__name__)

class AgentState(TypedDict):
    """LangGraph ì—ì´ì „íŠ¸ ìƒíƒœ"""
    messages: Annotated[list, add_messages]
    user_type: str
    session_id: str
    context: Dict[str, Any]
    tools_used: List[str]
    knowledge_retrieved: List[Dict[str, Any]]
    current_step: str
    reasoning: List[str]

class MedicalSearchInput(BaseModel):
    """ì˜ë£Œ ê²€ìƒ‰ ì…ë ¥ ìŠ¤í‚¤ë§ˆ"""
    query: str = Field(description="ê²€ìƒ‰ ì¿¼ë¦¬")
    user_type: str = Field(default="patient", description="ì‚¬ìš©ì ìœ í˜•")
    search_type: str = Field(default="hybrid", description="ê²€ìƒ‰ ìœ í˜•: vector, graph, hybrid")

class MedicalAnalysisInput(BaseModel):
    """ì˜ë£Œ ë¶„ì„ ì…ë ¥ ìŠ¤í‚¤ë§ˆ"""
    symptoms: List[str] = Field(description="ì¦ìƒ ëª©ë¡")
    patient_info: Dict[str, Any] = Field(default={}, description="í™˜ì ì •ë³´")
    analysis_type: str = Field(default="diagnosis", description="ë¶„ì„ ìœ í˜•")

@tool("medical_knowledge_search", args_schema=MedicalSearchInput)
def medical_knowledge_search(query: str, user_type: str = "patient", search_type: str = "hybrid") -> Dict[str, Any]:
    """ì˜ë£Œ ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ì •ë³´ ê²€ìƒ‰"""
    try:
        results = {"vector_results": [], "graph_results": {}, "combined_context": ""}
        
        if search_type in ["vector", "hybrid"]:
            # ë²¡í„° ê²€ìƒ‰
            vector_results = medical_vector_store.search_by_medical_context(
                query=query, 
                user_type=user_type
            )
            results["vector_results"] = vector_results[:3]
        
        if search_type in ["graph", "hybrid"]:
            # GraphRAG ê²€ìƒ‰
            graph_results = medical_graph_rag.graphrag_search(
                query=query,
                user_type=user_type,
                max_results=3
            )
            results["graph_results"] = graph_results
        
        # í†µí•© ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context_parts = []
        
        if results["vector_results"]:
            vector_context = "\\n".join([
                f"**{result['metadata'].get('title', 'No title')}**: {result['content'][:200]}..."
                for result in results["vector_results"]
            ])
            context_parts.append(f"ğŸ“š **ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼:**\\n{vector_context}")
        
        if results["graph_results"].get("graph_context"):
            context_parts.append(f"ğŸ”— **ì§€ì‹ ê·¸ë˜í”„:**\\n{results['graph_results']['graph_context']}")
        
        results["combined_context"] = "\\n\\n".join(context_parts)
        
        return {
            "success": True,
            "query": query,
            "user_type": user_type,
            "results": results,
            "summary": f"ê²€ìƒ‰ ì™„ë£Œ: ë²¡í„° {len(results['vector_results'])}ê°œ, ê·¸ë˜í”„ ì—”í‹°í‹° {results['graph_results'].get('num_entities', 0)}ê°œ"
        }
        
    except Exception as e:
        logger.error(f"Medical knowledge search error: {e}")
        return {
            "success": False,
            "error": str(e),
            "results": {"vector_results": [], "graph_results": {}, "combined_context": ""}
        }

@tool("symptom_analysis")
def symptom_analysis(symptoms: List[str], patient_info: Dict[str, Any] = {}) -> Dict[str, Any]:
    """ì¦ìƒ ë¶„ì„ ë° ì˜ˆë¹„ ì§„ë‹¨"""
    try:
        # ì¦ìƒ ê¸°ë°˜ ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰
        symptom_query = " ".join(symptoms)
        search_results = medical_knowledge_search.func(
            query=f"ì¦ìƒ {symptom_query}",
            user_type="doctor",
            search_type="hybrid"
        )
        
        # ë¶„ì„ ê²°ê³¼ êµ¬ì„±
        analysis = {
            "input_symptoms": symptoms,
            "patient_info": patient_info,
            "related_conditions": [],
            "recommended_tests": [],
            "urgency_level": "medium",
            "differential_diagnosis": []
        }
        
        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ê´€ë ¨ ì§ˆí™˜ ì¶”ì¶œ
        if search_results["success"]:
            for result in search_results["results"]["vector_results"]:
                if result["metadata"].get("document_type") == "guideline":
                    analysis["related_conditions"].append({
                        "condition": result["metadata"].get("title", "Unknown"),
                        "relevance": 1.0 - result["distance"],
                        "source": result["metadata"].get("source", "Unknown")
                    })
        
        # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ë¶„ì„
        high_risk_symptoms = ["ê°€ìŠ´ í†µì¦", "í˜¸í¡ê³¤ë€", "ì˜ì‹ ìƒìŒ", "ì‹¬í•œ ë‘í†µ"]
        if any(symptom in " ".join(symptoms) for symptom in high_risk_symptoms):
            analysis["urgency_level"] = "high"
            analysis["recommended_tests"].append("ì‘ê¸‰ì‹¤ ë°©ë¬¸")
        
        return {
            "success": True,
            "analysis": analysis,
            "search_context": search_results["results"]["combined_context"]
        }
        
    except Exception as e:
        logger.error(f"Symptom analysis error: {e}")
        return {
            "success": False,
            "error": str(e),
            "analysis": {}
        }

@tool("drug_interaction_check")
def drug_interaction_check(medications: List[str]) -> Dict[str, Any]:
    """ì•½ë¬¼ ìƒí˜¸ì‘ìš© í™•ì¸"""
    try:
        interactions = []
        
        # ê° ì•½ë¬¼ì— ëŒ€í•œ ì •ë³´ ê²€ìƒ‰
        for med in medications:
            search_result = medical_knowledge_search.func(
                query=f"ì•½ë¬¼ {med} ìƒí˜¸ì‘ìš©",
                user_type="doctor",
                search_type="vector"
            )
            
            if search_result["success"] and search_result["results"]["vector_results"]:
                interactions.append({
                    "medication": med,
                    "interactions": search_result["results"]["vector_results"][0]["content"][:300],
                    "source": search_result["results"]["vector_results"][0]["metadata"].get("source", "Unknown")
                })
        
        return {
            "success": True,
            "medications": medications,
            "interactions": interactions,
            "summary": f"{len(interactions)}ê°œ ì•½ë¬¼ì˜ ìƒí˜¸ì‘ìš© ì •ë³´ í™•ì¸"
        }
        
    except Exception as e:
        logger.error(f"Drug interaction check error: {e}")
        return {
            "success": False,
            "error": str(e),
            "interactions": []
        }

class MedicalAgent:
    """ì„œìš¸ì•„ì‚°ë³‘ì› ì˜ë£Œ AI ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        # ì˜ë£Œ ë„êµ¬ë“¤
        self.tools = [
            medical_knowledge_search,
            symptom_analysis, 
            drug_interaction_check
        ]
        
        # ì‚¬ìš©ì ìœ í˜•ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        self.system_prompts = {
            "patient": """ë‹¹ì‹ ì€ ì„œìš¸ì•„ì‚°ë³‘ì›ì˜ ì¹œê·¼í•œ ì˜ë£Œ ìƒë‹´ AIì…ë‹ˆë‹¤.
            
**ì—­í• :**
- í™˜ìì˜ ì§ˆë¬¸ì— ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹µë³€
- ì˜í•™ì  ì •ë³´ë¥¼ ì•ˆì „í•˜ê²Œ ì œê³µ
- í•„ìš”ì‹œ ì˜ë£Œì§„ ìƒë‹´ ê¶Œê³ 
- ì‘ê¸‰ ìƒí™©ì—ì„œëŠ” ì¦‰ì‹œ ì‘ê¸‰ì‹¤ ë°©ë¬¸ ì•ˆë‚´

**ì£¼ì˜ì‚¬í•­:**
- ì§„ë‹¨ì„ ëŒ€ì‹ í•˜ì§€ ì•ŠìŒì„ ëª…ì‹œ
- ë³µì¡í•œ ì˜í•™ ìš©ì–´ëŠ” ì‰½ê²Œ ì„¤ëª…
- ë¶ˆì•ˆê°ì„ ì£¼ì§€ ì•Šë„ë¡ ì‹ ì¤‘í•˜ê²Œ í‘œí˜„""",

            "doctor": """ë‹¹ì‹ ì€ ì„œìš¸ì•„ì‚°ë³‘ì›ì˜ ì „ë¬¸ ì˜ë£Œ AIì…ë‹ˆë‹¤.
            
**ì—­í• :**
- ì„ìƒ ì˜ì‚¬ê²°ì • ì§€ì›
- ìµœì‹  ì§„ë£Œ ê°€ì´ë“œë¼ì¸ ì œê³µ
- ê°ë³„ì§„ë‹¨ ë„ì›€
- ì•½ë¬¼ ì •ë³´ ë° ìƒí˜¸ì‘ìš© í™•ì¸

**ê¸°ëŠ¥:**
- ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
- ì¦ìƒ ë¶„ì„ ë° ì˜ˆë¹„ ì§„ë‹¨
- Evidence-based ë‹µë³€ ì œê³µ""",

            "researcher": """ë‹¹ì‹ ì€ ì„œìš¸ì•„ì‚°ë³‘ì›ì˜ ì˜ë£Œ ì—°êµ¬ AIì…ë‹ˆë‹¤.
            
**ì—­í• :**
- ìµœì‹  ì—°êµ¬ ë™í–¥ ì œê³µ
- ë°ì´í„° ë¶„ì„ ì§€ì›
- ì—°êµ¬ ë°©ë²•ë¡  ìë¬¸
- í†µê³„ì  í•´ì„ ë„ì›€

**íŠ¹ì§•:**
- Evidence-based medicine ê´€ì 
- ì—°êµ¬ ë…¼ë¬¸ ë° ë°ì´í„° í™œìš©
- ë¹„íŒì  ì‚¬ê³  ì§€ì›"""
        }
        
        # LangGraph ì´ˆê¸°í™”
        self.graph = self._build_graph()
    
    def _build_graph(self) -> StateGraph:
        """LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""
        # ì›Œí¬í”Œë¡œìš° ì •ì˜
        workflow = StateGraph(AgentState)
        
        # ë…¸ë“œë“¤ ì¶”ê°€
        workflow.add_node("classifier", self._classify_intent)
        workflow.add_node("knowledge_search", self._knowledge_search_node)
        workflow.add_node("symptom_analyzer", self._symptom_analysis_node)
        workflow.add_node("response_generator", self._generate_response)
        workflow.add_node("tools", ToolNode(self.tools))
        
        # ì—£ì§€ ì„¤ì •
        workflow.set_entry_point("classifier")
        
        workflow.add_conditional_edges(
            "classifier",
            self._route_intent,
            {
                "knowledge_search": "knowledge_search",
                "symptom_analysis": "symptom_analyzer",
                "direct_response": "response_generator"
            }
        )
        
        workflow.add_edge("knowledge_search", "response_generator")
        workflow.add_edge("symptom_analyzer", "response_generator") 
        workflow.add_edge("response_generator", END)
        
        return workflow.compile()
    
    def _classify_intent(self, state: AgentState) -> AgentState:
        """ì‚¬ìš©ì ì˜ë„ ë¶„ë¥˜"""
        try:
            last_message = state["messages"][-1]
            content = last_message.content if hasattr(last_message, 'content') else str(last_message)
            
            # ê°„ë‹¨í•œ ì˜ë„ ë¶„ë¥˜
            content_lower = content.lower()
            
            if any(keyword in content_lower for keyword in ["ì¦ìƒ", "ì•„í””", "í†µì¦", "ì—´", "ê¸°ì¹¨"]):
                state["current_step"] = "ì¦ìƒ ë¶„ì„"
                state["context"]["intent"] = "symptom_analysis"
            elif any(keyword in content_lower for keyword in ["ì•½", "ì²˜ë°©", "ë³µìš©", "ìƒí˜¸ì‘ìš©"]):
                state["current_step"] = "ì•½ë¬¼ ì •ë³´ ê²€ìƒ‰"
                state["context"]["intent"] = "drug_inquiry"
            else:
                state["current_step"] = "ì˜ë£Œ ì§€ì‹ ê²€ìƒ‰"
                state["context"]["intent"] = "knowledge_search"
            
            state["reasoning"].append(f"ì˜ë„ ë¶„ë¥˜ ì™„ë£Œ: {state['context']['intent']}")
            
        except Exception as e:
            logger.error(f"Intent classification error: {e}")
            state["context"]["intent"] = "knowledge_search"
            state["current_step"] = "ì˜ë£Œ ì§€ì‹ ê²€ìƒ‰ (ê¸°ë³¸)"
        
        return state
    
    def _route_intent(self, state: AgentState) -> str:
        """ì˜ë„ì— ë”°ë¥¸ ë¼ìš°íŒ…"""
        intent = state["context"].get("intent", "knowledge_search")
        
        if intent == "symptom_analysis":
            return "symptom_analysis"
        elif intent in ["drug_inquiry", "knowledge_search"]:
            return "knowledge_search"
        else:
            return "direct_response"
    
    def _knowledge_search_node(self, state: AgentState) -> AgentState:
        """ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰ ë…¸ë“œ"""
        try:
            last_message = state["messages"][-1]
            query = last_message.content if hasattr(last_message, 'content') else str(last_message)
            
            # ì§€ì‹ ê²€ìƒ‰ ìˆ˜í–‰ (ë„êµ¬ í•¨ìˆ˜ ì§ì ‘ í˜¸ì¶œ)
            search_result = medical_knowledge_search.func(
                query=query,
                user_type=state["user_type"],
                search_type="hybrid"
            )
            
            if search_result["success"]:
                state["knowledge_retrieved"].extend([search_result])
                state["reasoning"].append("ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ")
            else:
                state["reasoning"].append(f"ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {search_result.get('error', 'Unknown error')}")
            
            state["tools_used"].append("medical_knowledge_search")
            
        except Exception as e:
            logger.error(f"Knowledge search node error: {e}")
            state["reasoning"].append(f"ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        
        return state
    
    def _symptom_analysis_node(self, state: AgentState) -> AgentState:
        """ì¦ìƒ ë¶„ì„ ë…¸ë“œ"""
        try:
            last_message = state["messages"][-1]
            content = last_message.content if hasattr(last_message, 'content') else str(last_message)
            
            # ì¦ìƒ ì¶”ì¶œ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ)
            symptoms = []
            symptom_keywords = ["ë‘í†µ", "ë°œì—´", "ê¸°ì¹¨", "ê°€ìŠ´ í†µì¦", "í˜¸í¡ê³¤ë€", "ì–´ì§€ëŸ¬ì›€", "ë³µí†µ"]
            for keyword in symptom_keywords:
                if keyword in content:
                    symptoms.append(keyword)
            
            if not symptoms:
                symptoms = [content]  # ì „ì²´ ë‚´ìš©ì„ ì¦ìƒìœ¼ë¡œ ì²˜ë¦¬
            
            # ì¦ìƒ ë¶„ì„ ìˆ˜í–‰ (ë„êµ¬ í•¨ìˆ˜ ì§ì ‘ í˜¸ì¶œ)
            analysis_result = symptom_analysis.func(symptoms=symptoms)
            
            if analysis_result["success"]:
                state["knowledge_retrieved"].append(analysis_result)
                state["reasoning"].append(f"ì¦ìƒ ë¶„ì„ ì™„ë£Œ: {len(symptoms)}ê°œ ì¦ìƒ")
            else:
                state["reasoning"].append(f"ì¦ìƒ ë¶„ì„ ì‹¤íŒ¨: {analysis_result.get('error', 'Unknown error')}")
            
            state["tools_used"].append("symptom_analysis")
            
        except Exception as e:
            logger.error(f"Symptom analysis node error: {e}")
            state["reasoning"].append(f"ì¦ìƒ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        
        return state
    
    def _generate_response(self, state: AgentState) -> AgentState:
        """ì‘ë‹µ ìƒì„± ë…¸ë“œ"""
        try:
            # ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
            context_parts = []
            
            # ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€
            for knowledge in state["knowledge_retrieved"]:
                if "results" in knowledge and knowledge["results"].get("combined_context"):
                    context_parts.append(knowledge["results"]["combined_context"])
                elif "analysis" in knowledge:
                    context_parts.append(f"**ì¦ìƒ ë¶„ì„:**\\n{json.dumps(knowledge['analysis'], ensure_ascii=False, indent=2)}")
            
            combined_context = "\\n\\n".join(context_parts) if context_parts else "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ
            system_prompt = self.system_prompts.get(state["user_type"], self.system_prompts["patient"])
            
            # ì‚¬ìš©ì ì§ˆì˜
            last_message = state["messages"][-1]
            user_query = last_message.content if hasattr(last_message, 'content') else str(last_message)
            
            # ì „ì²´ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            full_prompt = f"""{system_prompt}

**ê²€ìƒ‰ëœ ì˜ë£Œ ì •ë³´:**
{combined_context}

**ì‚¬ìš©ì ì§ˆì˜:** {user_query}

**ì§€ì¹¨:**
- ìœ„ì˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ ì œê³µ
- ì‚¬ìš©ì ìœ í˜•({state["user_type"]})ì— ë§ëŠ” ìˆ˜ì¤€ìœ¼ë¡œ ì„¤ëª…
- ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” ì¶”ê°€ ìƒë‹´ì„ ê¶Œìœ 
- ì‘ê¸‰ ìƒí™© ì‹œì—ëŠ” ì¦‰ì‹œ ì˜ë£Œì§„ ìƒë‹´ ì•ˆë‚´

**ë‹µë³€:**"""
            
            # Qwen ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„±
            if qwen_model.model and qwen_model.tokenizer:
                response = qwen_model.generate_response(
                    query=full_prompt,
                    user_type=state["user_type"],
                    max_length=1000
                )
            else:
                response = f"""ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•„ ê¸°ë³¸ ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤.

**ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½:**
{combined_context[:500]}...

**ê¶Œê³ ì‚¬í•­:**
- ì •í™•í•œ ì§„ë‹¨ì„ ìœ„í•´ ì „ë¬¸ì˜ ìƒë‹´ì„ ë°›ìœ¼ì‹œê¸° ë°”ëë‹ˆë‹¤.
- ì‘ê¸‰ ìƒí™© ì‹œì—ëŠ” ì¦‰ì‹œ ì‘ê¸‰ì‹¤ì„ ë°©ë¬¸í•˜ì„¸ìš”.
- ì¶”ê°€ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¸ì˜í•˜ì„¸ìš”."""
            
            # AI ì‘ë‹µ ë©”ì‹œì§€ ì¶”ê°€
            ai_message = AIMessage(content=response)
            state["messages"].append(ai_message)
            
            state["current_step"] = "ì‘ë‹µ ìƒì„± ì™„ë£Œ"
            state["reasoning"].append("AI ì‘ë‹µ ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"Response generation error: {e}")
            error_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            ai_message = AIMessage(content=error_response)
            state["messages"].append(ai_message)
            state["reasoning"].append(f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        
        return state
    
    async def process_query(self, 
                           query: str, 
                           user_type: str = "patient", 
                           session_id: str = None) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì§ˆì˜ ì²˜ë¦¬"""
        try:
            session_id = session_id or f"session_{uuid.uuid4().hex[:8]}"
            
            # ì´ˆê¸° ìƒíƒœ ì„¤ì •
            initial_state: AgentState = {
                "messages": [HumanMessage(content=query)],
                "user_type": user_type,
                "session_id": session_id,
                "context": {},
                "tools_used": [],
                "knowledge_retrieved": [],
                "current_step": "ì‹œì‘",
                "reasoning": []
            }
            
            # LangGraph ì‹¤í–‰
            final_state = await self.graph.ainvoke(initial_state)
            
            # ê²°ê³¼ ì •ë¦¬
            ai_response = final_state["messages"][-1].content if final_state["messages"] else "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            return {
                "response": ai_response,
                "session_id": session_id,
                "user_type": user_type,
                "tools_used": final_state["tools_used"],
                "reasoning": final_state["reasoning"],
                "knowledge_count": len(final_state["knowledge_retrieved"]),
                "current_step": final_state["current_step"]
            }
            
        except Exception as e:
            logger.error(f"Query processing error: {e}")
            return {
                "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆì˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "session_id": session_id,
                "user_type": user_type,
                "tools_used": [],
                "reasoning": [f"ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"],
                "knowledge_count": 0,
                "current_step": "ì˜¤ë¥˜ ë°œìƒ"
            }

# ì „ì—­ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤
medical_agent = MedicalAgent()

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    import asyncio
    
    async def test_agent():
        # í…ŒìŠ¤íŠ¸ ì§ˆì˜ë“¤
        test_queries = [
            ("ê³ í˜ˆì••ì´ ìˆëŠ”ë° ì–´ë–¤ ì•½ì„ ë³µìš©í•´ì•¼ í•˜ë‚˜ìš”?", "patient"),
            ("ë‘í†µê³¼ ë°œì—´ ì¦ìƒì´ ìˆìŠµë‹ˆë‹¤", "patient"),
            ("ACE ì–µì œì œì™€ ARBì˜ ì°¨ì´ì ì„ ì•Œë ¤ì£¼ì„¸ìš”", "doctor")
        ]
        
        for query, user_type in test_queries:
            print(f"\\nì§ˆì˜: {query} (ì‚¬ìš©ì: {user_type})")
            result = await medical_agent.process_query(query, user_type)
            print(f"ì‘ë‹µ: {result['response'][:200]}...")
            print(f"ì‚¬ìš©ëœ ë„êµ¬: {result['tools_used']}")
            print(f"ì§€ì‹ ê°œìˆ˜: {result['knowledge_count']}")
    
    asyncio.run(test_agent())